{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e1e7f3c-83a8-4dda-8d9a-02423a23fa03",
   "metadata": {},
   "source": [
    "# Kubernetes MCP diagnostics with Llama Stack Agents (RHOAI)\n",
    "\n",
    "This notebook demonstrates how to use the **Llama Stack Agents API** to perform\n",
    "Kubernetes diagnostics through a **Model Context Protocol (MCP) server**.\n",
    "\n",
    "- It is designed to run against the **RHOAI Llama Stack image**  \n",
    "  `rhoai/odh-llama-stack-core-rhel9:v3.0`\n",
    "- It connects to the Llama Stack instance exposed by that image (via `LLAMA_BASE_URL`).\n",
    "- It uses the **Agents API** (not the `/v1/responses` file_search flow) to:\n",
    "  - Create an agent with MCP tools\n",
    "  - Create a session\n",
    "  - Run a single diagnostic “turn”\n",
    "  - Show which MCP tools were called and the final answer\n",
    "\n",
    "You will configure:\n",
    "\n",
    "- `LLAMA_BASE_URL` – URL of your Llama Stack service\n",
    "- `REMOTE_OCP_MCP_URL` – URL of your Kubernetes MCP server (e.g. the k8s MCP in your demo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b87b6b1-8575-40aa-8025-eab2bb604f24",
   "metadata": {},
   "source": [
    "## 1. Install dependencies\n",
    "\n",
    "This cell installs the `llama-stack-client` Python SDK (matching the server\n",
    "version used by `rhoai/odh-llama-stack-core-rhel9:v3.0`), plus helpers for\n",
    "environment variables and coloured output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43605001-7d28-4d23-9ebf-a2fe739a28ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet \"llama-stack-client==0.3.0\" python-dotenv termcolor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba23e92d-b5b4-4823-a835-c99ac35331f4",
   "metadata": {},
   "source": [
    "## 2. Connect to Llama Stack and list available models\n",
    "\n",
    "This cell:\n",
    "\n",
    "- Loads configuration from a `.env` file (if present).\n",
    "- Connects to the Llama Stack instance exposed by the\n",
    "  `rhoai/odh-llama-stack-core-rhel9:v3.0` image via `LLAMA_BASE_URL`.\n",
    "- Lists available models and selects a suitable LLM (preferring the vLLM-backed one).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e30bbd4-64eb-4c1d-8212-f35a194dde47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://lsd-llama-milvus-inline-service.llama-stack-demo.svc.cluster.local:8321/v1/models \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Llama Stack server: http://lsd-llama-milvus-inline-service.llama-stack-demo.svc.cluster.local:8321\n",
      "\n",
      "Available models:\n",
      " - granite-embedding-125m (type=embedding, provider=sentence-transformers)\n",
      " - vllm-inference/llama-4-scout-17b-16e-w4a16 (type=llm, provider=vllm-inference)\n",
      " - sentence-transformers/nomic-ai/nomic-embed-text-v1.5 (type=embedding, provider=sentence-transformers)\n",
      "\n",
      "Using model: vllm-inference/llama-4-scout-17b-16e-w4a16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from termcolor import cprint\n",
    "from llama_stack_client import LlamaStackClient\n",
    "\n",
    "# Load environment variables from .env (LLAMA_BASE_URL, REMOTE_OCP_MCP_URL, etc.)\n",
    "load_dotenv()\n",
    "\n",
    "# Base URL of the Llama Stack server\n",
    "base_url = os.getenv(\n",
    "    \"LLAMA_BASE_URL\",\n",
    "    \"http://lsd-llama-milvus-inline-service.llama-stack-demo.svc.cluster.local:8321\",\n",
    ").rstrip(\"/\")\n",
    "\n",
    "client = LlamaStackClient(base_url=base_url)\n",
    "print(f\"Connected to Llama Stack server: {base_url}\")\n",
    "\n",
    "# List models so we can see what's available\n",
    "models = list(client.models.list())\n",
    "print(\"\\nAvailable models:\")\n",
    "for m in models:\n",
    "    ident = getattr(m, \"identifier\", None) or getattr(m, \"model_id\", None) or str(m)\n",
    "    print(f\" - {ident} (type={getattr(m, 'model_type', None)}, provider={getattr(m, 'provider_id', None)})\")\n",
    "\n",
    "# Prefer a vLLM-backed LLM if available, otherwise just take the first LLM\n",
    "llm = next(\n",
    "    (\n",
    "        m\n",
    "        for m in models\n",
    "        if getattr(m, \"model_type\", None) == \"llm\"\n",
    "        and getattr(m, \"provider_id\", None) == \"vllm-inference\"\n",
    "    ),\n",
    "    None,\n",
    ")\n",
    "\n",
    "if not llm:\n",
    "    llm = next((m for m in models if getattr(m, \"model_type\", None) == \"llm\"), None)\n",
    "\n",
    "assert llm, \"No LLM models available on Llama Stack\"\n",
    "\n",
    "model_id = getattr(llm, \"identifier\", None) or getattr(llm, \"model_id\", None)\n",
    "print(f\"\\nUsing model: {model_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b48561-36ea-47bb-b897-fcd2fa690e39",
   "metadata": {},
   "source": [
    "## 3. Define the Kubernetes MCP diagnostic prompt\n",
    "\n",
    "This cell defines a detailed **system prompt** that instructs the agent how to:\n",
    "\n",
    "- Use the Kubernetes MCP tools exposed by your MCP server\n",
    "- Always call `pods_list_in_namespace` and `pods_log` for real pods\n",
    "- Avoid inventing pod names (it must use exactly what appears in the pod list)\n",
    "- Summarise findings and provide next steps for an SRE/operator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feece24d-23cc-432f-8700-a2deb5b6362e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prompt = \"\"\"\n",
    "You are a Kubernetes diagnostics assistant working with a Model Context Protocol (MCP) server.\n",
    "Your job is to investigate incidents using ONLY the Kubernetes MCP tools and then explain your findings.\n",
    "\n",
    "Available MCP tools (do NOT invent new ones):\n",
    "- configuration_view\n",
    "- events_list\n",
    "- helm_list\n",
    "- namespaces_list\n",
    "- nodes_log\n",
    "- nodes_stats_summary\n",
    "- nodes_top\n",
    "- pods_get\n",
    "- pods_list\n",
    "- pods_list_in_namespace\n",
    "- pods_log\n",
    "- pods_top\n",
    "- projects_list\n",
    "- resources_get\n",
    "- resources_list\n",
    "\n",
    "High-level workflow for ANY incident / “something is broken” question:\n",
    "\n",
    "PHASE 0 – Discover what exists in the project\n",
    "1. If a Kubernetes namespace is mentioned (e.g. \"special-payment-project\"), treat it as the target namespace.\n",
    "2. You MUST call:\n",
    "   - pods_list_in_namespace(namespace=<ns>)          # inventory pods\n",
    "   - resources_list(apiVersion=\"v1\",      kind=\"Service\",    namespace=<ns>)   # inventory Services\n",
    "   - resources_list(apiVersion=\"apps/v1\", kind=\"Deployment\", namespace=<ns>)   # inventory Deployments\n",
    "   - Optionally, on OpenShift:\n",
    "     resources_list(apiVersion=\"route.openshift.io/v1\", kind=\"Route\", namespace=<ns>)\n",
    "\n",
    "PHASE 1 – Drill into the most relevant workloads\n",
    "3. From the pod list, pick 1–3 pods whose names look most relevant to the question\n",
    "   (e.g. contain \"api\", \"frontend\", \"payment\", \"checkout\").\n",
    "4. VERY IMPORTANT NAMING RULES:\n",
    "   - You may ONLY use pod names that appear EXACTLY in the pods_list_in_namespace output.\n",
    "   - You MUST NOT create new pod names by combining words (e.g. \"payment-api\") if that exact string\n",
    "     was not present in the pods_list_in_namespace table.\n",
    "   - If you want logs for a payment-related pod, you MUST choose the closest REAL name from the list\n",
    "     (for example \"checkout-api-84bff5f68d-2p775\") and use that exact name in pods_log.\n",
    "\n",
    "5. You MUST call pods_log for at least one of the existing pods:\n",
    "   - The \"name\" argument to pods_log MUST be copied exactly from the pods_list_in_namespace output.\n",
    "   - It is allowed (and encouraged) to call pods_log for more than one relevant pod.\n",
    "\n",
    "6. Optionally:\n",
    "   - Call events_list(namespace=<ns>) to look for Warning/Error events related to those pods.\n",
    "   - Use resources_get(...) if you need details for a specific Service or Deployment already seen in resources_list.\n",
    "\n",
    "Failure handling:\n",
    "- If pods_log returns \"pod not found\" or a similar error, you MUST:\n",
    "  - Re-check the pods_list_in_namespace output, and\n",
    "  - Immediately call pods_log again using a pod name that definitely exists.\n",
    "\n",
    "Hard rules:\n",
    "- You MUST call at least one MCP tool for EVERY answer.\n",
    "- For incident / error questions, you MUST:\n",
    "  - Call pods_list_in_namespace(namespace=<ns>) AND\n",
    "  - Call pods_log(...) for at least one pod that actually exists.\n",
    "- You MUST NOT talk about “checking logs” unless you have actually called pods_log in this conversation.\n",
    "- You MUST NOT mention or use tools that are not in the list above (e.g. no services_list_in_namespace).\n",
    "\n",
    "When you answer, ALWAYS:\n",
    "- Start by listing which MCP tools you called and with which key arguments.\n",
    "- Summarise what you observed:\n",
    "  - Pods (names + status from pods_list_in_namespace)\n",
    "  - Important log snippets from pods_log (even 1–2 lines is fine)\n",
    "  - Any notable events or resource issues (from events_list / resources_list)\n",
    "- Give your best diagnosis based on that evidence.\n",
    "- End with 2–3 concrete next steps for an SRE/operator.\n",
    "\n",
    "If tools fail or return nothing useful:\n",
    "- Explicitly say which tools you tried and what they returned (e.g. “pod not found”, “no events”).\n",
    "- State clearly that the evidence is inconclusive and what a human should check next.\n",
    "\"\"\".strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5efebf-075b-4d51-912f-f6bc02087f02",
   "metadata": {},
   "source": [
    "## 4. Create an Agent with Kubernetes MCP tools (Agents API)\n",
    "\n",
    "This cell uses the **Llama Stack Agents API** to create an `Agent` that:\n",
    "\n",
    "- Uses the selected model from the `rhoai/odh-llama-stack-core-rhel9:v3.0` Llama Stack instance\n",
    "- Is configured with the Kubernetes MCP server as a tool (`type: \"mcp\"`)\n",
    "- Uses the system prompt defined above as its `instructions`\n",
    "\n",
    "The MCP server URL is taken from:\n",
    "\n",
    "- `REMOTE_OCP_MCP_URL` (in your `.env`), or\n",
    "- falls back to the in-cluster default route used in the demo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cabe1c9b-c805-4e09-9f6b-61278a7f2d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Kubernetes MCP server: http://kubernetes-mcp-server.llama-stack-demo.svc.cluster.local:8080/sse\n",
      "Agent created with tools: [{'type': 'mcp', 'server_url': 'http://kubernetes-mcp-server.llama-stack-demo.svc.cluster.local:8080/sse', 'server_label': 'kubernetes-mcp'}]\n"
     ]
    }
   ],
   "source": [
    "from llama_stack_client import Agent\n",
    "\n",
    "# URL for the Kubernetes MCP server (adjust default to your real MCP route if needed)\n",
    "ocp_mcp_url = os.getenv(\n",
    "    \"REMOTE_OCP_MCP_URL\",\n",
    "    \"http://kubernetes-mcp-server.llama-stack-demo.svc.cluster.local:8080/sse\",\n",
    ").rstrip(\"/\")\n",
    "\n",
    "print(f\"Using Kubernetes MCP server: {ocp_mcp_url}\")\n",
    "\n",
    "tools_spec = [\n",
    "    {\n",
    "        \"type\": \"mcp\",\n",
    "        \"server_url\": ocp_mcp_url,\n",
    "        \"server_label\": \"kubernetes-mcp\",\n",
    "        # you can add \"require_approval\": \"never\" later if you want\n",
    "    }\n",
    "]\n",
    "\n",
    "agent = Agent(\n",
    "    client,\n",
    "    model=model_id,\n",
    "    instructions=model_prompt,\n",
    "    tools=tools_spec,\n",
    ")\n",
    "\n",
    "print(\"Agent created with tools:\", tools_spec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d468f499-e190-4745-aa1b-0b780d3b82b1",
   "metadata": {},
   "source": [
    "## 5. Run a diagnostic turn (create session + create turn)\n",
    "\n",
    "This cell:\n",
    "\n",
    "1. Creates a lightweight **Agent session** (via the Agents API).\n",
    "2. Sends a single user message describing the incident\n",
    "   (HTTP 502 in the `special-payment-project` namespace).\n",
    "3. Executes a non-streaming turn and captures the result.\n",
    "\n",
    "The agent will internally:\n",
    "\n",
    "- Discover available MCP tools\n",
    "- Call Kubernetes tools like `pods_list_in_namespace`, `pods_log`, `events_list`, etc.\n",
    "- Produce a natural-language summary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "384897a2-bd95-4976-be49-a0096d0740df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://lsd-llama-milvus-inline-service.llama-stack-demo.svc.cluster.local:8321/v1/conversations \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://lsd-llama-milvus-inline-service.llama-stack-demo.svc.cluster.local:8321/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mUser message:\u001b[0m\n",
      "I'm getting 'Payment failed: HTTP 502' in the project 'special-payment-project', please investigate.\n",
      "\n",
      "Session ID: conv_17e465e635937ab6d029524c258923f4447025a892493b65\n",
      "\n",
      "Raw result type: <class 'llama_stack_client.types.response_object.ResponseObject'>\n"
     ]
    }
   ],
   "source": [
    "from termcolor import cprint\n",
    "\n",
    "question = (\n",
    "    \"I'm getting 'Payment failed: HTTP 502' in the project 'special-payment-project', please investigate.\"\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": question},\n",
    "]\n",
    "\n",
    "cprint(\"User message:\", \"green\")\n",
    "print(question)\n",
    "\n",
    "# 1) Create a session (lightweight)\n",
    "session = agent.create_session(session_name=\"k8s-mcp-demo\")\n",
    "session_id = getattr(session, \"id\", None) or getattr(session, \"session_id\", None) or str(session)\n",
    "print(\"\\nSession ID:\", session_id)\n",
    "\n",
    "# 2) Run a single non-streaming turn\n",
    "result = agent.create_turn(\n",
    "    messages=messages,\n",
    "    session_id=session_id,\n",
    "    stream=False,\n",
    ")\n",
    "\n",
    "print(\"\\nRaw result type:\", type(result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba296a23-9766-42d0-88eb-15da5b0c4d20",
   "metadata": {},
   "source": [
    "## 6. Inspect MCP calls and the assistant’s answer\n",
    "\n",
    "This cell pretty-prints the **execution trace** of the Agent:\n",
    "\n",
    "- Which MCP tools were discovered (`mcp_list_tools`)\n",
    "- Which tools were actually called (`mcp_call` entries)\n",
    "- Key snippets of tool output (logs, pod lists, events)\n",
    "- The final assistant answer\n",
    "\n",
    "This is useful in the demo to show **how** the Agents API orchestrates MCP tools\n",
    "behind the scenes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d58e6f10-cd0f-4de3-bfd2-3295ba1cd478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m\n",
      "=== MCP tools discovered ===\u001b[0m\n",
      "configuration_view, events_list, helm_list, namespaces_list, nodes_log, nodes_stats_summary, nodes_top, pods_get, pods_list, pods_list_in_namespace, pods_log, pods_top, projects_list, resources_get, resources_list\n",
      "\u001b[33m\n",
      "=== MCP calls made ===\u001b[0m\n",
      "- pods_list_in_namespace({\"namespace\": \"special-payment-project\"})\n",
      "    NAMESPACE                 APIVERSION   KIND   NAME                                READY   STATUS    RESTARTS   AGE   IP            NODE                                         NOMINATED NODE   READINESS GATES   LABELS\n",
      "    special-payment-project   v1           Pod    checkout-api-84bff5f68d-2p775       1/1     Running   0          23h   10.128.2.96   ip-10-0-117-105.us-east-2.compute.internal   <none>\n",
      "    ... [truncated]\n",
      "\n",
      "- resources_list({\"apiVersion\": \"v1\", \"kind\": \"Service\", \"namespace\": \"special-payment-project\"})\n",
      "    NAMESPACE                 APIVERSION   KIND      NAME                TYPE           CLUSTER-IP       EXTERNAL-IP                                                   PORT(S)    AGE   SELECTOR                LABELS\n",
      "    special-payment-project   v1           Service   card-gateway-dns    ExternalName   <none>           card-gateway-sandbx.payments-provider-sim.svc.cluster.local   5678/TCP   23h   <none>   \n",
      "    ... [truncated]\n",
      "\n",
      "- resources_list({\"apiVersion\": \"apps/v1\", \"kind\": \"Deployment\", \"namespace\": \"special-payment-project\"})\n",
      "    NAMESPACE                 APIVERSION   KIND         NAME                READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES                                                                                     SELECTOR                LABELS\n",
      "    special-payment-project   apps/v1      Deployment   checkout-api        1/1     1            1           23h   api          image-registry.openshift-image\n",
      "    ... [truncated]\n",
      "\n",
      "- pods_log({\"name\": \"payment-api-84bff5f68d-2p775\", \"namespace\": \"special-payment-project\"})\n",
      "\n",
      "- pods_list_in_namespace({\"namespace\": \"special-payment-project\"})\n",
      "    NAMESPACE                 APIVERSION   KIND   NAME                                READY   STATUS    RESTARTS   AGE   IP            NODE                                         NOMINATED NODE   READINESS GATES   LABELS\n",
      "    special-payment-project   v1           Pod    checkout-api-84bff5f68d-2p775       1/1     Running   0          23h   10.128.2.96   ip-10-0-117-105.us-east-2.compute.internal   <none>\n",
      "    ... [truncated]\n",
      "\n",
      "- resources_list({\"apiVersion\": \"v1\", \"kind\": \"Service\", \"namespace\": \"special-payment-project\"})\n",
      "    NAMESPACE                 APIVERSION   KIND      NAME                TYPE           CLUSTER-IP       EXTERNAL-IP                                                   PORT(S)    AGE   SELECTOR                LABELS\n",
      "    special-payment-project   v1           Service   card-gateway-dns    ExternalName   <none>           card-gateway-sandbx.payments-provider-sim.svc.cluster.local   5678/TCP   23h   <none>   \n",
      "    ... [truncated]\n",
      "\n",
      "- resources_list({\"apiVersion\": \"apps/v1\", \"kind\": \"Deployment\", \"namespace\": \"special-payment-project\"})\n",
      "    NAMESPACE                 APIVERSION   KIND         NAME                READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES                                                                                     SELECTOR                LABELS\n",
      "    special-payment-project   apps/v1      Deployment   checkout-api        1/1     1            1           23h   api          image-registry.openshift-image\n",
      "    ... [truncated]\n",
      "\n",
      "- pods_log({\"name\": \"checkout-api-84bff5f68d-2p775\", \"namespace\": \"special-payment-project\"})\n",
      "    INFO:     Started server process [1]\n",
      "    INFO:     Waiting for application startup.\n",
      "    INFO:     Application startup complete.\n",
      "    INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n",
      "    INFO:     10.128.2.26:53934 - \"POST /api/checkout HTTP/1.1\" 200 OK\n",
      "    checkout upstream_error url=http://card-gateway-dns:5678 err=ConnectError: [Errno -5] No address associated with hostname elapsed_s=0.033\n",
      "    INF\n",
      "    ... [truncated]\n",
      "\n",
      "\u001b[36m\n",
      "=== Assistant answer ===\u001b[0m\n",
      "## MCP Tools Called\n",
      "- `pods_list_in_namespace(namespace=\"special-payment-project\")`\n",
      "- `resources_list(apiVersion=\"v1\", kind=\"Service\", namespace=\"special-payment-project\")`\n",
      "- `resources_list(apiVersion=\"apps/v1\", kind=\"Deployment\", namespace=\"special-payment-project\")`\n",
      "- `pods_log(name=\"checkout-api-84bff5f68d-2p775\", namespace=\"special-payment-project\")`\n",
      "\n",
      "## Observations\n",
      "- **Pods:** \n",
      "  - `checkout-api-84bff5f68d-2p775` (Running, 1/1)\n",
      "  - `checkout-frontend-6cb956cfb-fpr5h` (Running, 1/1)\n",
      "- **Services:**\n",
      "  - `card-gateway-dns` (ExternalName, points to `card-gateway-sandbx.payments-provider-sim.svc.cluster.local:5678`)\n",
      "  - `checkout-api` (ClusterIP, port 8000)\n",
      "  - `checkout-frontend` (ClusterIP, port 8080)\n",
      "- **Deployments:**\n",
      "  - `checkout-api` (1/1, Available)\n",
      "  - `checkout-frontend` (1/1, Available)\n",
      "- **Logs from `checkout-api-84bff5f68d-2p775`:**\n",
      "  - Show repeated `upstream_error` messages indicating a connection issue to `card-gateway-dns:5678`.\n",
      "  - Specific error: `ConnectError: [Errno -5] No address associated with hostname`.\n",
      "  - Multiple `502 Bad Gateway` responses for POST requests to `/api/checkout`.\n",
      "\n",
      "## Diagnosis\n",
      "The error `Payment failed: HTTP 502` is likely caused by a connection issue between the `checkout-api` pod and the `card-gateway-dns` service. The logs indicate that the `checkout-api` pod is unable to resolve or connect to `card-gateway-dns`, resulting in a `502 Bad Gateway` response.\n",
      "\n",
      "## Next Steps\n",
      "1. **Verify DNS Resolution:**\n",
      "   - Check if `card-gateway-sandbx.payments-provider-sim.svc.cluster.local` is resolvable from within the cluster.\n",
      "   - Use `nslookup` or `dig` within a pod to verify DNS resolution.\n",
      "\n",
      "2. **Check Service Endpoints:**\n",
      "   - Verify that the `card-gateway-sandbx.payments-provider-sim` service exists and has the correct endpoints.\n",
      "\n",
      "3. **Review Network Policies:**\n",
      "   - Ensure that there are no network policies restricting communication between `checkout-api` and `card-gateway-dns`.\n",
      "\n",
      "By following these steps, you should be able to identify and resolve the connectivity issue causing the `HTTP 502` errors.\n"
     ]
    }
   ],
   "source": [
    "from textwrap import indent\n",
    "\n",
    "def show_mcp_response(response, max_output_chars: int = 400, show_raw: bool = False):\n",
    "    \"\"\"\n",
    "    Pretty-print MCP tool usage and the assistant's answer\n",
    "    from a Llama Stack ResponseObject (via Agent API).\n",
    "    \"\"\"\n",
    "    # LlamaStackClient ResponseObject has .to_dict()\n",
    "    if hasattr(response, \"to_dict\"):\n",
    "        data = response.to_dict()\n",
    "    else:\n",
    "        data = response\n",
    "\n",
    "    # --- 1) Show MCP tools discovered (from mcp_list_tools) ---\n",
    "    mcp_list = [item for item in data.get(\"output\", []) if item.get(\"type\") == \"mcp_list_tools\"]\n",
    "\n",
    "    cprint(\"\\n=== MCP tools discovered ===\", \"yellow\")\n",
    "    if mcp_list:\n",
    "        tools = mcp_list[0].get(\"tools\", [])\n",
    "        names = [t.get(\"name\") for t in tools if isinstance(t, dict)]\n",
    "        print(\", \".join(sorted(set(n for n in names if n))) or \"(none)\")\n",
    "    else:\n",
    "        print(\"(no mcp_list_tools entry)\")\n",
    "\n",
    "    # --- 2) Show actual MCP tool calls (mcp_call entries) ---\n",
    "    mcp_calls = [item for item in data.get(\"output\", []) if item.get(\"type\") == \"mcp_call\"]\n",
    "\n",
    "    cprint(\"\\n=== MCP calls made ===\", \"yellow\")\n",
    "    if not mcp_calls:\n",
    "        print(\"(no MCP tool calls were executed)\")\n",
    "    else:\n",
    "        for call in mcp_calls:\n",
    "            name = call.get(\"name\")\n",
    "            args = call.get(\"arguments\")\n",
    "            out = call.get(\"output\", \"\") or \"\"\n",
    "            print(f\"- {name}({args})\")\n",
    "            if out:\n",
    "                snippet = out[:max_output_chars]\n",
    "                print(indent(snippet, \"    \"))\n",
    "                if len(out) > max_output_chars:\n",
    "                    print(\"    ... [truncated]\")\n",
    "            print()\n",
    "\n",
    "    # --- 3) Extract assistant's final answer text ---\n",
    "    cprint(\"\\n=== Assistant answer ===\", \"cyan\")\n",
    "\n",
    "    # Try convenience field first\n",
    "    text = getattr(response, \"output_text\", None) if hasattr(response, \"output_text\") else None\n",
    "\n",
    "    # Fallback: pull from the final message content\n",
    "    if text in (None, \"\") and isinstance(data, dict):\n",
    "        for item in data.get(\"output\", []):\n",
    "            if item.get(\"type\") == \"message\":\n",
    "                for part in item.get(\"content\", []):\n",
    "                    if part.get(\"type\") == \"output_text\":\n",
    "                        text = part.get(\"text\", \"\")\n",
    "                        break\n",
    "                if text is not None:\n",
    "                    break\n",
    "\n",
    "    if text and str(text).strip():\n",
    "        print(text)\n",
    "    else:\n",
    "        print(\"(Assistant returned an empty message – no natural-language answer.)\")\n",
    "        if show_raw:\n",
    "            print(\"\\n--- Raw response (debug) ---\")\n",
    "            pprint(data)\n",
    "\n",
    "show_mcp_response(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccce4e1d-e2fd-4266-a8fe-c69e78f87350",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
