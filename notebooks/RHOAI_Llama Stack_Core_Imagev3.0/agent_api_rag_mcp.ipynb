{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "271ceb86-e928-4a5e-a0a2-5ac4a383fd4b",
   "metadata": {},
   "source": [
    "# MCP-First Diagnostics + RAG Correlation (Special Payment Project)\n",
    "\n",
    "This notebook shows a **two-phase AIOps flow** running on Llama Stack:\n",
    "\n",
    "1. **Phase 1 ‚Äì Live diagnostics with MCP (Kubernetes):**  \n",
    "   We use the Llama Stack **Responses API** with an **MCP tool** that talks to the\n",
    "   OpenShift/Kubernetes cluster (pods, logs, Services, etc.).  \n",
    "   The LLM produces a **‚Äúcluster findings‚Äù** summary based purely on live data\n",
    "   from the `special-payment-project` namespace.\n",
    "\n",
    "2. **Phase 2 ‚Äì Knowledge-base correlation with RAG:**  \n",
    "   We use a Llama Stack **Agent** with the `file_search` tool bound to a specific\n",
    "   vector store containing documentation about the *Special Payment Project*.  \n",
    "   The agent takes the incident description + cluster findings and looks for\n",
    "   **matching known issues / runbooks** in the KB to explain likely root cause\n",
    "   and propose next steps.\n",
    "\n",
    "This notebook is designed for **demo and explainability**:\n",
    "- No helper functions ‚Äì everything is step-by-step.\n",
    "- Clear separation between **diagnostics (MCP)** and **correlation (RAG)**.\n",
    "- Easy to show each phase independently in a live demo.\n",
    "\n",
    "> ‚úÖ Tested against:  \n",
    "> - Llama Stack server image: `rhoai/odh-llama-stack-core-rhel9:v3.0`  \n",
    "> - Model: `vllm-inference/llama-4-scout-17b-16e-w4a16`  \n",
    "> - Vector store ID: `vs_c246cf6a-40a4-425b-80c2-4d4e3f438fb1`  \n",
    "> - Kubernetes MCP server: `kubernetes-mcp-server.llama-stack-demo.svc.cluster.local:8080`\n",
    "\n",
    "You can adapt this notebook to your own environment by updating the\n",
    "**demo configuration variables** in the next cell (or via environment\n",
    "variables in a `.env` file).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148c0278-0df7-4712-805b-6bfda8a0cd28",
   "metadata": {},
   "source": [
    "## Cell 1 ‚Äì Configure demo settings (easy to change)\n",
    "\n",
    "This cell defines the **demo configuration** in one place:\n",
    "\n",
    "- `LLAMA_BASE_URL_CONFIG` ‚Äì HTTP URL of your Llama Stack server  \n",
    "- `PREFERRED_MODEL_ID_CONFIG` ‚Äì optional model identifier to prefer  \n",
    "- `VECTOR_STORE_ID_CONFIG` ‚Äì vector store with your Special Payment Project docs  \n",
    "- `REMOTE_OCP_MCP_URL_CONFIG` ‚Äì URL of your Kubernetes MCP server (SSE endpoint)\n",
    "\n",
    "For a quick test, just edit these string values directly.\n",
    "\n",
    "> üîÅ Advanced:  \n",
    "> You can also override these via environment variables (`LLAMA_BASE_URL`,\n",
    "> `MODEL_ID`, `VECTOR_STORE_ID`, `REMOTE_OCP_MCP_URL`) in a `.env` file ‚Äì\n",
    "> the notebook will prefer env vars if present.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "655a8eb4-6d62-4bc1-8bbd-aa260e34826b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Demo configuration variables defined.\n",
      "LLAMA_BASE_URL_CONFIG          = http://lsd-llama-milvus-inline-service.llama-stack-demo.svc.cluster.local:8321\n",
      "PREFERRED_MODEL_ID_CONFIG      = vllm-inference/llama-4-scout-17b-16e-w4a16\n",
      "VECTOR_STORE_ID_CONFIG         = vs_c246cf6a-40a4-425b-80c2-4d4e3f438fb1\n",
      "REMOTE_OCP_MCP_URL_CONFIG      = http://kubernetes-mcp-server.llama-stack-demo.svc.cluster.local:8080/sse\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 - Demo configuration: update these if needed\n",
    "\n",
    "# Llama Stack HTTP base URL (no trailing slash)\n",
    "LLAMA_BASE_URL_CONFIG = \"http://lsd-llama-milvus-inline-service.llama-stack-demo.svc.cluster.local:8321\"\n",
    "\n",
    "# Optional: prefer a specific model; leave as \"\" to auto-select an LLM\n",
    "PREFERRED_MODEL_ID_CONFIG = \"vllm-inference/llama-4-scout-17b-16e-w4a16\"\n",
    "\n",
    "# Vector store containing Special Payment Project docs (Confluence export, etc.)\n",
    "VECTOR_STORE_ID_CONFIG = \"vs_c246cf6a-40a4-425b-80c2-4d4e3f438fb1\"\n",
    "\n",
    "# Kubernetes MCP server URL providing access to the cluster (SSE endpoint)\n",
    "REMOTE_OCP_MCP_URL_CONFIG = \"http://kubernetes-mcp-server.llama-stack-demo.svc.cluster.local:8080/sse\"\n",
    "\n",
    "print(\"‚úÖ Demo configuration variables defined.\")\n",
    "print(\"LLAMA_BASE_URL_CONFIG          =\", LLAMA_BASE_URL_CONFIG)\n",
    "print(\"PREFERRED_MODEL_ID_CONFIG      =\", PREFERRED_MODEL_ID_CONFIG or \"(auto-select LLM)\")\n",
    "print(\"VECTOR_STORE_ID_CONFIG         =\", VECTOR_STORE_ID_CONFIG)\n",
    "print(\"REMOTE_OCP_MCP_URL_CONFIG      =\", REMOTE_OCP_MCP_URL_CONFIG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a390cc-0435-46dc-9b10-bf50bc8e8e7c",
   "metadata": {},
   "source": [
    "## Cell 2 ‚Äì Install dependencies and connect to Llama Stack\n",
    "\n",
    "This cell:\n",
    "\n",
    "1. Installs the Python packages we need.\n",
    "2. Imports the libraries.\n",
    "3. Loads any environment variables from `.env`.\n",
    "4. Resolves the **effective** values for:\n",
    "   - `LLAMA_BASE_URL`\n",
    "   - `REMOTE_OCP_MCP_URL`\n",
    "   - `VECTOR_STORE_ID`\n",
    "5. Creates a `LlamaStackClient` and prints the key endpoints in use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "360f2a35-3d14-4e7e-bda6-87173de7e056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "‚úÖ Connected to Llama Stack server: http://lsd-llama-milvus-inline-service.llama-stack-demo.svc.cluster.local:8321\n",
      "‚û°Ô∏è  Using Kubernetes MCP server: http://kubernetes-mcp-server.llama-stack-demo.svc.cluster.local:8080/sse\n",
      "‚û°Ô∏è  Using vector store: vs_c246cf6a-40a4-425b-80c2-4d4e3f438fb1\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 - Install deps, import libraries, connect to Llama Stack\n",
    "\n",
    "%pip install --quiet \"llama-stack-client==0.3.0\" python-dotenv termcolor\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from termcolor import cprint\n",
    "from llama_stack_client import LlamaStackClient\n",
    "\n",
    "# Load .env if present (LLAMA_BASE_URL, MODEL_ID, VECTOR_STORE_ID, REMOTE_OCP_MCP_URL, etc.)\n",
    "load_dotenv()\n",
    "\n",
    "# Resolve effective settings: env vars override notebook defaults\n",
    "LLAMA_BASE_URL = os.getenv(\"LLAMA_BASE_URL\", LLAMA_BASE_URL_CONFIG).rstrip(\"/\")\n",
    "REMOTE_OCP_MCP_URL = os.getenv(\"REMOTE_OCP_MCP_URL\", REMOTE_OCP_MCP_URL_CONFIG).rstrip(\"/\")\n",
    "VECTOR_STORE_ID = os.getenv(\"VECTOR_STORE_ID\", VECTOR_STORE_ID_CONFIG)\n",
    "\n",
    "# Create Llama Stack client\n",
    "client = LlamaStackClient(base_url=LLAMA_BASE_URL)\n",
    "print(f\"‚úÖ Connected to Llama Stack server: {LLAMA_BASE_URL}\")\n",
    "print(f\"‚û°Ô∏è  Using Kubernetes MCP server: {REMOTE_OCP_MCP_URL}\")\n",
    "print(f\"‚û°Ô∏è  Using vector store: {VECTOR_STORE_ID}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005b3eaf-1e1c-4cef-9943-8e2fd2441fa1",
   "metadata": {},
   "source": [
    "## Cell 3 ‚Äì List available models and select an LLM\n",
    "\n",
    "Here we:\n",
    "\n",
    "1. List all models exposed by the Llama Stack server.\n",
    "2. Try to honour the `PREFERRED_MODEL_ID_CONFIG` (or `MODEL_ID` env var) if provided.\n",
    "3. If no preferred model is set or not found, we:\n",
    "   - Prefer an `llm` model served by the `vllm-inference` provider.\n",
    "   - Otherwise, fall back to any model with `model_type == \"llm\"`.\n",
    "\n",
    "The chosen `model_id` will be used for:\n",
    "\n",
    "- **Phase 1** diagnostics (Responses API + MCP)\n",
    "- **Phase 2** correlation (Agent + file_search)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97b82087-3e62-483e-9a9e-e09aef155ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://lsd-llama-milvus-inline-service.llama-stack-demo.svc.cluster.local:8321/v1/models \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available models:\n",
      " - granite-embedding-125m | type= embedding | provider= sentence-transformers\n",
      " - vllm-inference/llama-4-scout-17b-16e-w4a16 | type= llm | provider= vllm-inference\n",
      " - sentence-transformers/nomic-ai/nomic-embed-text-v1.5 | type= embedding | provider= sentence-transformers\n",
      "\n",
      "‚úÖ Preferred model found: vllm-inference/llama-4-scout-17b-16e-w4a16\n",
      "\n",
      "üéØ Using LLM model: vllm-inference/llama-4-scout-17b-16e-w4a16\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 - List models and pick an LLM\n",
    "\n",
    "# Allow environment variable override for the model id as well\n",
    "MODEL_ID_OVERRIDE = os.getenv(\"MODEL_ID\", PREFERRED_MODEL_ID_CONFIG)\n",
    "\n",
    "models = list(client.models.list())\n",
    "print(\"\\nAvailable models:\")\n",
    "for m in models:\n",
    "    ident = getattr(m, \"identifier\", None) or getattr(m, \"model_id\", None) or str(m)\n",
    "    mtype = getattr(m, \"model_type\", None)\n",
    "    prov = getattr(m, \"provider_id\", None)\n",
    "    print(\" -\", ident, \"| type=\", mtype, \"| provider=\", prov)\n",
    "\n",
    "llm = None\n",
    "\n",
    "# 1) If a preferred/override model id is set, try to use it\n",
    "if MODEL_ID_OVERRIDE:\n",
    "    llm = next(\n",
    "        (\n",
    "            m for m in models\n",
    "            if (getattr(m, \"identifier\", None) or getattr(m, \"model_id\", None)) == MODEL_ID_OVERRIDE\n",
    "        ),\n",
    "        None,\n",
    "    )\n",
    "    if llm:\n",
    "        print(f\"\\n‚úÖ Preferred model found: {MODEL_ID_OVERRIDE}\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è Preferred model '{MODEL_ID_OVERRIDE}' not found, falling back to auto-selection.\")\n",
    "\n",
    "# 2) If no preferred model or not found, auto-select\n",
    "if not llm:\n",
    "    llm = next(\n",
    "        (\n",
    "            m for m in models\n",
    "            if getattr(m, \"model_type\", None) == \"llm\"\n",
    "            and getattr(m, \"provider_id\", None) == \"vllm-inference\"\n",
    "        ),\n",
    "        None,\n",
    "    )\n",
    "\n",
    "if not llm:\n",
    "    llm = next((m for m in models if getattr(m, \"model_type\", None) == \"llm\"), None)\n",
    "\n",
    "assert llm, \"No LLM models available on Llama Stack\"\n",
    "\n",
    "model_id = getattr(llm, \"identifier\", None) or getattr(llm, \"model_id\", None)\n",
    "print(f\"\\nüéØ Using LLM model: {model_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12807fe-2a39-4f47-b0f7-4e61c154e9b1",
   "metadata": {},
   "source": [
    "## Cell 4 ‚Äì Define basic RAG agent instructions and create the Agent\n",
    "\n",
    "In this cell we:\n",
    "\n",
    "1. Define **simple RAG agent instructions**:\n",
    "   - The agent is a **Special Payment Project KB assistant**.\n",
    "   - It only uses `file_search` (no live cluster access).\n",
    "   - It takes an incident description + cluster findings and looks for\n",
    "     matching known issues / runbooks.\n",
    "\n",
    "2. Create a `rag_agent`:\n",
    "   - Bound to `model_id`.\n",
    "   - Bound to the `file_search` tool scoped to `VECTOR_STORE_ID`.\n",
    "   - With these basic instructions assigned to the agent.\n",
    "\n",
    "Later, we‚Äôll layer on **more detailed correlation instructions** for a specific turn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2c1bd9c-494b-480d-b2b9-24a5e8a52b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RAG Agent initialised with basic KB instructions and file_search tool.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 - Basic RAG agent instructions and construction\n",
    "\n",
    "from llama_stack_client import Agent\n",
    "\n",
    "rag_agent_instructions = \"\"\"\n",
    "You are a knowledge-base assistant for the Special Payment Project.\n",
    "\n",
    "You ONLY have access to the knowledge base (Confluence docs etc.) via file_search.\n",
    "You DO NOT have direct access to the live Kubernetes cluster.\n",
    "\n",
    "You will be given:\n",
    "- An incident description, and\n",
    "- A summary of cluster findings from a prior diagnostics pass (pods, logs, services).\n",
    "\n",
    "Your job:\n",
    "- Look up relevant information in the knowledge base about the Special Payment Project.\n",
    "- Try to match the cluster findings to any known issues, incident writeups, or runbooks.\n",
    "- Explain the most likely root cause(s) in clear language.\n",
    "- Propose concrete next steps or runbook actions for an SRE.\n",
    "\n",
    "Ignore generic documentation unless it clearly relates to the given cluster findings.\n",
    "Be concise, focused, and practical.\n",
    "\"\"\".strip()\n",
    "\n",
    "rag_tools_spec = [\n",
    "    {\n",
    "        \"type\": \"file_search\",\n",
    "        \"vector_store_ids\": [VECTOR_STORE_ID],\n",
    "    }\n",
    "]\n",
    "\n",
    "rag_agent = Agent(\n",
    "    client,\n",
    "    model=model_id,\n",
    "    instructions=rag_agent_instructions,\n",
    "    tools=rag_tools_spec,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ RAG Agent initialised with basic KB instructions and file_search tool.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6bb07c-7ff9-4ac0-aa33-757ee420cb73",
   "metadata": {},
   "source": [
    "## Cell 5 ‚Äì Define MCP diagnostics instructions\n",
    "\n",
    "This cell defines the **diagnostics instructions** for the MCP phase.\n",
    "\n",
    "The assistant:\n",
    "\n",
    "- MUST call real MCP tools (pods, logs, Services, Deployments, Events).\n",
    "- Cannot see any docs yet.\n",
    "- Must highlight:\n",
    "  - HTTP 5xx\n",
    "  - DNS errors\n",
    "  - Timeouts\n",
    "  - TLS failures\n",
    "  - Concrete config values (e.g. `spec.externalName` for ExternalName Services).\n",
    "\n",
    "The result is a **‚Äúcluster findings‚Äù** narrative that we pass into the RAG phase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0275c95-eaa8-4796-a6df-ae616240fb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ MCP diagnostics instructions defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 - Define the MCP diagnostics instructions\n",
    "\n",
    "mcp_instructions = \"\"\"\n",
    "You are a Kubernetes diagnostics assistant using MCP tools.\n",
    "\n",
    "You MUST actually call MCP tools to answer the question.\n",
    "Do NOT simulate tool calls or outputs.\n",
    "Do NOT write fake examples like [pods_list_in_namespace(...)];\n",
    "instead, emit real MCP tool calls so the server can execute them.\n",
    "\n",
    "You do NOT have access to any documentation or knowledge base in this phase.\n",
    "You MUST NOT guess what the ‚Äúcorrect‚Äù hostname, port, or configuration should be.\n",
    "Only report what you can observe directly from MCP tool outputs.\n",
    "\n",
    "Your focus in the target namespace (for example 'special-payment-project') is to:\n",
    "- Use pods_list_in_namespace to discover workloads.\n",
    "- Use pods_log on relevant pods (especially anything in the path of the failing request,\n",
    "  such as API or frontend pods).\n",
    "- Use resources_list / resources_get to inspect Services and Deployments.\n",
    "- Use events_list if you need to check for recent warnings/errors.\n",
    "\n",
    "When logs show HTTP 5xx or upstream connection errors:\n",
    "- Identify which upstream hostname or Service is being called (for example from a URL\n",
    "  like 'http://some-service:port').\n",
    "- Fetch the Service definition for that upstream using resources_get.\n",
    "- If the Service is of type ExternalName, include in your findings both:\n",
    "  - the Service name, and\n",
    "  - the exact value of spec.externalName as returned by the MCP tool.\n",
    "\n",
    "In your findings output, you MUST:\n",
    "- Quote key log lines that look suspicious (5xx, DNS errors, timeouts, TLS failures, etc.).\n",
    "- List the pods and Services that are clearly in the request path.\n",
    "- For any ExternalName Services you inspected, make sure the actual externalName value\n",
    "  appears verbatim somewhere in your summary, so it can be compared later.\n",
    "\n",
    "If a value looks unusual (for example something that looks like a typo), you may say that it\n",
    "\"appears suspicious or possibly misconfigured\", but you MUST NOT invent or state the exact\n",
    "value it ‚Äúshould‚Äù be. The exact expected value will be determined in a later knowledge-base\n",
    "phase.\n",
    "\n",
    "Your output should be a concise \"cluster findings\" narrative that highlights:\n",
    "- Which pods/services are involved in the path of the failing request.\n",
    "- Key log lines and observed configuration values that look suspicious.\n",
    "- Any obvious misconfigurations you can see (wrong ports, bad selectors, odd ExternalName, etc.),\n",
    "  always quoting the concrete values you observed.\n",
    "\n",
    "Do NOT try to guess business impact or historical context here.\n",
    "Simply describe what looks wrong or suspicious in the live cluster.\n",
    "\"\"\".strip()\n",
    "\n",
    "print(\"‚úÖ MCP diagnostics instructions defined.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8b6482-ad74-4ae6-83c9-5e62e15f3168",
   "metadata": {},
   "source": [
    "## Cell 6 ‚Äì Run MCP diagnostics and capture cluster findings\n",
    "\n",
    "In this cell we:\n",
    "\n",
    "1. Define the **incident question**:\n",
    "   - `'Payment failed: HTTP 502'` in the Special Payment Project checkout flow.\n",
    "\n",
    "2. Call the Llama Stack **Responses API** with:\n",
    "   - MCP diagnostics instructions as a `system` message.\n",
    "   - The incident question as a `user` message.\n",
    "   - An MCP tool pointing to the Kubernetes MCP server.\n",
    "\n",
    "3. Extract a plain-text **`cluster_findings`** summary:\n",
    "   - Prefer `response.output_text` if available.\n",
    "   - Otherwise, scan the message output for `output_text`.\n",
    "\n",
    "4. Print the cluster findings for use in the next phase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8323baa7-a295-4a07-912b-13a66e01d8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mIncident question:\u001b[0m\n",
      "We are seeing 'Payment failed: HTTP 502' errors in the Special Payment Project checkout flow (namespace: special-payment-project). Please investigate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://lsd-llama-milvus-inline-service.llama-stack-demo.svc.cluster.local:8321/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MCP output item types: ['mcp_list_tools', 'mcp_call', 'mcp_call', 'mcp_call', 'mcp_call', 'mcp_call', 'message']\n",
      "\u001b[33m\n",
      "--- Cluster findings (MCP summary) ---\u001b[0m\n",
      "The checkout flow in the Special Payment Project (namespace: special-payment-project) appears to be encountering errors due to a misconfigured ExternalName Service.\n",
      "\n",
      "The `card-gateway-dns` Service is defined as an ExternalName type, which maps to the hostname `card-gateway-sandbx.payments-provider-sim.svc.cluster.local`. However, in the logs of the `checkout-api` pod, there is an error message indicating a `ConnectError` with the message `[Errno -5] No address associated with hostname`. This suggests that the DNS resolution for the ExternalName Service is failing.\n",
      "\n",
      "The likely cause of this issue is a typo in the `externalName` value of the `card-gateway-dns` Service. The correct value should be `card-gateway-sandbox.payments-provider-sim.svc.cluster.local` instead of `card-gateway-sandbx.payments-provider-sim.svc.cluster.local`.\n",
      "\n",
      "The pods and Services that are clearly in the request path are:\n",
      "\n",
      "* `checkout-api-84bff5f68d-dlm2k` (Pod)\n",
      "* `checkout-frontend-6cb956cfb-fpr5h` (Pod)\n",
      "* `card-gateway-dns` (Service)\n",
      "* `checkout-api` (Service)\n",
      "* `checkout-frontend` (Service)\n",
      "\n",
      "The key log lines that look suspicious are:\n",
      "\n",
      "* `checkout upstream_error url=http://card-gateway-dns:5678 err=ConnectError: [Errno -5] No address associated with hostname elapsed_s=0.032`\n",
      "* `INFO:     10.128.2.26:57542 - \\\"POST /api/checkout HTTP/1.1\\\" 502 Bad Gateway`\n",
      "\n",
      "The observed configuration values that look suspicious are:\n",
      "\n",
      "* `externalName: card-gateway-sandbx.payments-provider-sim.svc.cluster.local` (typo in the hostname)\n"
     ]
    }
   ],
   "source": [
    "# Cell 6 - Run MCP diagnostics and extract a \"cluster findings\" summary\n",
    "\n",
    "incident_question = (\n",
    "    \"We are seeing 'Payment failed: HTTP 502' errors in the Special Payment Project \"\n",
    "    \"checkout flow (namespace: special-payment-project). Please investigate.\"\n",
    ")\n",
    "\n",
    "cprint(\"Incident question:\", \"green\")\n",
    "print(incident_question)\n",
    "\n",
    "mcp_messages = [\n",
    "    {\"role\": \"system\", \"content\": mcp_instructions},\n",
    "    {\"role\": \"user\", \"content\": incident_question},\n",
    "]\n",
    "\n",
    "mcp_response = client.responses.create(\n",
    "    model=model_id,\n",
    "    input=mcp_messages,\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"mcp\",\n",
    "            \"server_url\": REMOTE_OCP_MCP_URL,\n",
    "            \"server_label\": \"kubernetes-mcp\",\n",
    "            \"require_approval\": \"never\",\n",
    "        }\n",
    "    ],\n",
    "    temperature=0.0,\n",
    "    max_infer_iters=8,\n",
    ")\n",
    "\n",
    "# Turn into a dict for inspection\n",
    "if hasattr(mcp_response, \"to_dict\"):\n",
    "    mcp_data = mcp_response.to_dict()\n",
    "else:\n",
    "    mcp_data = mcp_response\n",
    "\n",
    "# Show what kinds of outputs we got (tool calls, messages, etc.)\n",
    "output_types = [item.get(\"type\") for item in mcp_data.get(\"output\", [])]\n",
    "print(\"\\nMCP output item types:\", output_types)\n",
    "\n",
    "# Extract a \"cluster findings\" text:\n",
    "# Prefer response.output_text, else scan the message outputs\n",
    "cluster_findings = getattr(mcp_response, \"output_text\", None)\n",
    "if not cluster_findings:\n",
    "    for item in mcp_data.get(\"output\", []):\n",
    "        if item.get(\"type\") == \"message\":\n",
    "            for part in item.get(\"content\", []):\n",
    "                if part.get(\"type\") == \"output_text\":\n",
    "                    cluster_findings = part.get(\"text\", \"\")\n",
    "                    break\n",
    "            if cluster_findings:\n",
    "                break\n",
    "\n",
    "cluster_findings = cluster_findings or \"\"\n",
    "\n",
    "cprint(\"\\n--- Cluster findings (MCP summary) ---\", \"yellow\")\n",
    "print(cluster_findings if cluster_findings.strip() else \"(no findings text returned)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11919265-6719-4b04-9d50-c77f6a9c2c2a",
   "metadata": {},
   "source": [
    "## Cell 7 ‚Äì Define RAG correlation instructions for this turn\n",
    "\n",
    "Here we define **detailed correlation instructions** that sit on top of the\n",
    "basic RAG agent behaviour:\n",
    "\n",
    "- How to compare **observed** vs **expected** config values.\n",
    "- How to treat mismatches as strong evidence.\n",
    "- How to quote KB snippets and produce a small evidence section.\n",
    "- Whitelisted **Reference document** titles.\n",
    "\n",
    "We‚Äôll pass these as a `system` message for this specific RAG turn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05d8dbdd-b3f7-460d-be4b-7c623af9904f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RAG correlation instructions defined (natural, demo-friendly).\n"
     ]
    }
   ],
   "source": [
    "# Cell 7 - RAG correlation instructions used for this turn (lighter, demo-friendly)\n",
    "\n",
    "rag_correlation_instructions = \"\"\"\n",
    "You are a knowledge-base assistant for the Special Payment Project.\n",
    "\n",
    "You are given:\n",
    "- An incident description.\n",
    "- A structured summary of cluster findings from a diagnostics pass that already\n",
    "  inspected pods, logs, and services.\n",
    "\n",
    "The cluster findings may include:\n",
    "- Concrete configuration values (for example hostnames, ports, externalName targets,\n",
    "  Service types, selectors, URLs).\n",
    "- Log snippets showing HTTP 5xx, connection errors, DNS failures, TLS issues, etc.\n",
    "- Short notes about which pods and Services appear to sit in the request path.\n",
    "\n",
    "You have access to a set of Special Payment Project documents stored in a knowledge base\n",
    "(e.g. exported from Confluence). Their titles and section headings may change over time.\n",
    "\n",
    "Using ONLY the knowledge base (via file_search), you MUST:\n",
    "- Look for issues, configuration notes, or design sections that match these findings.\n",
    "- Pay particular attention to:\n",
    "  - Expected configuration values (for example, expected hostnames, ports, URL patterns,\n",
    "    or Service types).\n",
    "  - Error patterns that resemble the logs in the findings (HTTP 5xx, DNS errors,\n",
    "    timeouts, TLS failures, etc.).\n",
    "- Prefer project-specific documentation about the Special Payment Project over generic\n",
    "  Kubernetes documentation when both are available.\n",
    "\n",
    "When the KB documents an expected configuration value and the cluster findings show\n",
    "a different observed value, you MUST:\n",
    "- Explicitly describe the mismatch in your own words (for example: ‚Äúthe Service in the\n",
    "  cluster points to X, but the documentation says it should point to Y‚Äù).\n",
    "- Treat such a mismatch as strong evidence of a misconfiguration.\n",
    "- Clearly state that this configuration mismatch is the most likely root cause in this\n",
    "  situation, rather than just listing generic ‚Äúpossible causes‚Äù.\n",
    "\n",
    "If the observed values in the cluster match what the KB describes as expected, you should:\n",
    "- NOT blame a configuration typo by default.\n",
    "- Instead, consider other causes mentioned in the KB (for example: backend service down,\n",
    "  wrong port open, network policy restrictions, TLS expiry, application bugs) based on\n",
    "  the cluster findings.\n",
    "\n",
    "EVIDENCE AND REFERENCING:\n",
    "- Do NOT invent document titles or section names.\n",
    "- Do NOT include pseudo-tool calls like [knowledge_search(...)] or [file_search(...)]\n",
    "  in your final answer. Just describe what you found in natural language.\n",
    "- When you rely on the KB for an expected value, configuration detail, or known issue,\n",
    "  include a short quote (1‚Äì2 sentences) from the KB that supports your conclusion.\n",
    "  The quote MUST be something that could plausibly appear verbatim in the KB.\n",
    "- Prefer quoting project-specific content (for example, descriptions of Special Payment\n",
    "  Project services, namespaces, or hostnames) over generic Kubernetes descriptions.\n",
    "\n",
    "REFERENCE DOCUMENT (WHITELISTED TITLES ONLY):\n",
    "- At the end of your answer, you MUST add a small reference section in this format:\n",
    "\n",
    "  Key KB evidence:\n",
    "  - \"<short quote from the KB that supports your conclusion>\"\n",
    "  - (optionally up to 2 more bullets if they are crucial)\n",
    "\n",
    "  Reference document:\n",
    "  - \"<ONE title from the allowed list below>\"\n",
    "\n",
    "- The Reference document line MUST be exactly one of the following strings:\n",
    "  - \"Special Payment Project ‚Äì Overview & Context\"\n",
    "  - \"Special Payment Project ‚Äì Application Architecture\"\n",
    "  - \"Special Payment Project ‚Äì Deployment & Configuration\"\n",
    "  - \"Special Payment Project ‚Äì Networking & External Dependencies\"\n",
    "  - \"Special Payment Project ‚Äì Observability & Alerts\"\n",
    "\n",
    "- You MUST NOT write any other value for Reference document.\n",
    "- You MUST NOT invent new titles or paraphrase these titles.\n",
    "- If you are uncertain which document the evidence came from, choose the one that\n",
    "  best matches the content based on its title. For DNS and ExternalName behaviour,\n",
    "  prefer \"Special Payment Project ‚Äì Networking & External Dependencies\".\n",
    "\n",
    "In all cases:\n",
    "- Explain the most likely root cause(s) in this specific scenario, grounded in both\n",
    "  the cluster findings and the documentation.\n",
    "- Explicitly reference which observed values you are comparing against which expected\n",
    "  values from the KB (for example: ‚ÄúexternalName in the cluster is X, the KB says it\n",
    "  should be Y‚Äù).\n",
    "- Suggest concrete next steps for an SRE (for example, config changes, rollbacks,\n",
    "  additional checks to perform).\n",
    "\n",
    "If the KB is inconclusive, say so, mention what kind of information you looked for,\n",
    "and suggest what a human should investigate next.\n",
    "Be concise and practical.\n",
    "\"\"\".strip()\n",
    "\n",
    "print(\"‚úÖ RAG correlation instructions defined (natural, demo-friendly).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d0d9f4-a3c6-40b6-b8ce-52e17a34551c",
   "metadata": {},
   "source": [
    "## Cell 8 ‚Äì Run the RAG Agent with MCP findings\n",
    "\n",
    "Now we switch to **Phase 2 ‚Äì Knowledge-base correlation**:\n",
    "\n",
    "1. Build messages:\n",
    "   - A `system` message with the **RAG correlation instructions**.\n",
    "   - A `user` message containing:\n",
    "     - The incident description.\n",
    "     - The cluster findings summary.\n",
    "\n",
    "2. Call the `rag_agent` we created earlier:\n",
    "   - The agent already knows it should use `file_search` on the Special Payment Project vector store.\n",
    "\n",
    "3. Extract and print the **final explanation**:\n",
    "   - Root cause analysis grounded in:\n",
    "     - Live cluster findings\n",
    "     - Special Payment Project documentation\n",
    "   - Suggested remediation / next steps\n",
    "   - Evidence + whitelisted reference document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5cde5ae-8367-44f1-a768-3ccd834f1a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://lsd-llama-milvus-inline-service.llama-stack-demo.svc.cluster.local:8321/v1/conversations \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://lsd-llama-milvus-inline-service.llama-stack-demo.svc.cluster.local:8321/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m\n",
      "=== Final RAG explanation (KB-backed RCA + next steps) ===\u001b[0m\n",
      "The incident description and cluster findings indicate that the Special Payment Project's checkout flow is encountering 'Payment failed: HTTP 502' errors due to a misconfigured ExternalName Service. \n",
      "\n",
      "The `card-gateway-dns` Service is defined with an ExternalName type that maps to `card-gateway-sandbx.payments-provider-sim.svc.cluster.local`. However, the logs of the `checkout-api` pod show a `ConnectError` with the message `[Errno -5] No address associated with hostname`, suggesting that the DNS resolution for the ExternalName Service is failing.\n",
      "\n",
      "According to the Special Payment Project ‚Äì Networking & External Dependencies documentation: \n",
      "\"The card-gateway-dns Service should point to card-gateway-sandbox.payments-provider-sim.svc.cluster.local\".\n",
      "\n",
      "Comparing the observed configuration value `card-gateway-sandbx.payments-provider-sim.svc.cluster.local` with the expected value `card-gateway-sandbox.payments-provider-sim.svc.cluster.local`, there is a clear typo in the `externalName` value. \n",
      "\n",
      "This configuration mismatch is the most likely root cause of the issue. \n",
      "\n",
      "The next steps for an SRE would be to:\n",
      "1. Correct the typo in the `externalName` value of the `card-gateway-dns` Service.\n",
      "2. Verify that the DNS resolution for the ExternalName Service is successful after the correction.\n",
      "3. Monitor the checkout flow for any further errors.\n",
      "\n",
      "Key KB evidence:\n",
      "- \"The card-gateway-dns Service should point to card-gateway-sandbox.payments-provider-sim.svc.cluster.local\"\n",
      " \n",
      "Reference document:\n",
      "- \"Special Payment Project ‚Äì Networking & External Dependencies\"\n"
     ]
    }
   ],
   "source": [
    "# Cell 8 - Run the RAG Agent against the MCP cluster findings\n",
    "\n",
    "rag_messages = [\n",
    "    {\"role\": \"system\", \"content\": rag_correlation_instructions},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            \"Incident description:\\n\"\n",
    "            f\"{incident_question}\\n\\n\"\n",
    "            \"Cluster findings from MCP diagnostics:\\n\"\n",
    "            f\"{cluster_findings}\"\n",
    "        ),\n",
    "    },\n",
    "]\n",
    "\n",
    "# Create a session for this demo run\n",
    "rag_session = rag_agent.create_session(session_name=\"mcp-first-rag-demo\")\n",
    "rag_session_id = (\n",
    "    getattr(rag_session, \"id\", None)\n",
    "    or getattr(rag_session, \"session_id\", None)\n",
    "    or str(rag_session)\n",
    ")\n",
    "\n",
    "rag_result = rag_agent.create_turn(\n",
    "    messages=rag_messages,\n",
    "    session_id=rag_session_id,\n",
    "    stream=False,\n",
    ")\n",
    "\n",
    "# Extract the final explanation text\n",
    "final_explanation = getattr(rag_result, \"output_text\", None)\n",
    "\n",
    "if not final_explanation and hasattr(rag_result, \"to_dict\"):\n",
    "    rag_data = rag_result.to_dict()\n",
    "    for item in rag_data.get(\"output\", []):\n",
    "        if item.get(\"type\") == \"message\":\n",
    "            for part in item.get(\"content\", []):\n",
    "                if part.get(\"type\") == \"output_text\":\n",
    "                    final_explanation = part.get(\"text\", \"\")\n",
    "                    break\n",
    "            if final_explanation:\n",
    "                break\n",
    "\n",
    "final_explanation = final_explanation or \"\"\n",
    "\n",
    "cprint(\"\\n=== Final RAG explanation (KB-backed RCA + next steps) ===\", \"cyan\")\n",
    "print(final_explanation if final_explanation.strip() else \"(no RAG explanation text returned)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5424d311-743f-4bb5-874d-6bd70f14cb9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
