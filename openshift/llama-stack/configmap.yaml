kind: ConfigMap
apiVersion: v1
metadata:
  name: lsd-run
data:
  run.yaml: |+
    version: 2

    apis:
      - agents
      - datasetio
      - eval
      - inference
      - safety
      - scoring
      - telemetry
      - tool_runtime
      - vector_io
      - files

    image_name: rh

    inference_store:
      type: sqlite
      db_path: /opt/app-root/src/.llama/distributions/rh/inference_store.db

    metadata_store:
      type: sqlite
      db_path: /opt/app-root/src/.llama/distributions/rh/registry.db

    models:
      - model_id: granite-embedding-125m
        model_type: embedding
        provider_id: sentence-transformers
        provider_model_id: ibm-granite/granite-embedding-125m-english
        metadata:
          embedding_dimension: 768

    providers:
      agents:
        - provider_id: meta-reference
          provider_type: inline::meta-reference
          config:
            persistence_store:
              type: sqlite
              db_path: /opt/app-root/src/.llama/distributions/rh/agents_store.db
            responses_store:
              type: sqlite
              db_path: /opt/app-root/src/.llama/distributions/rh/responses_store.db

      datasetio:
        - provider_id: huggingface
          provider_type: remote::huggingface
          config:
            kvstore:
              type: sqlite
              db_path: /opt/app-root/src/.llama/distributions/rh/huggingface_datasetio.db
        - provider_id: localfs
          provider_type: inline::localfs
          config:
            kvstore:
              type: sqlite
              db_path: /opt/app-root/src/.llama/distributions/rh/localfs_datasetio.db

      eval:
        - provider_id: trustyai_lmeval
          provider_type: remote::trustyai_lmeval
          module: llama_stack_provider_lmeval==0.2.4
          config:
            base_url: https://mistral-small-24b-w8a8-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com:443/v1
            use_k8s: true

      files:
        - provider_id: meta-reference-files
          provider_type: inline::localfs
          config:
            storage_dir: /opt/app-root/src/.llama/distributions/rh/files
            metadata_store:
              type: sqlite
              db_path: /opt/app-root/src/.llama/distributions/rh/files_metadata.db

      inference:
        - provider_id: vllm-inference
          provider_type: remote::vllm
          config:
            url: ${env.VLLM_URL}
            api_token: ${env.VLLM_API_TOKEN}
            max_tokens: ${env.VLLM_MAX_TOKENS}
            tls_verify: ${env.VLLM_TLS_VERIFY}
        - provider_id: sentence-transformers
          provider_type: inline::sentence-transformers
          config: {}

      safety:
        - provider_id: trustyai_fms
          provider_type: remote::trustyai_fms
          module: llama_stack_provider_trustyai_fms==0.2.2
          config:
            shields: {}

      scoring:
        - provider_id: basic
          provider_type: inline::basic
          config: {}
        - provider_id: llm-as-judge
          provider_type: inline::llm-as-judge
          config: {}
        - provider_id: braintrust
          provider_type: inline::braintrust
          config:
            openai_api_key: ""   # prevent EnvVarError; fill later if needed

      telemetry:
        - provider_id: meta-reference
          provider_type: inline::meta-reference
          config:
            service_name: ""
            sinks: console,sqlite
            sqlite_db_path: /opt/app-root/src/.llama/distributions/rh/trace_store.db

      tool_runtime:
        - provider_id: brave-search
          provider_type: remote::brave-search
          config:
            api_key: ""      # safe default
            max_results: 3
        - provider_id: tavily-search
          provider_type: remote::tavily-search
          config:
            api_key: ""      # safe default
            max_results: 3
        - provider_id: rag-runtime
          provider_type: inline::rag-runtime
          config: {}
        - provider_id: model-context-protocol
          provider_type: remote::model-context-protocol
          config: {}

      vector_io:
        - provider_id: milvus
          provider_type: inline::milvus
          config:
            db_path: /opt/app-root/src/.llama/distributions/rh/milvus.db
            kvstore:
              type: sqlite
              db_path: /opt/app-root/src/.llama/distributions/rh/milvus_registry.db

    tool_groups:
      - toolgroup_id: builtin::websearch
        provider_id: tavily-search
      - toolgroup_id: builtin::rag
        provider_id: rag-runtime

    vector_dbs: []
    scoring_fns: []

    server:
      port: 8321

    shields: []